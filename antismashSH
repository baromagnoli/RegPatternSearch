#!/bin/bash -f
#SBATCH --partition=SP2                        # Define a partição do SLURM onde o job será executado.
#SBATCH --ntasks=1                             # Número de tarefas, ou seja, só uma tarefa será executada.
#SBATCH --cpus-per-task=20                     # Número de CPUs por tarefa (aqui, 20 CPUs por tarefa).
#SBATCH -J aloca-1-cpu                         # Nome do job, para facilitar a identificação no SLURM.
#SBATCH --time=10:00:00                        # Tempo máximo de execução do job (aqui, 10 horas).
# Se você não especificar, o default é 8 horas, mas o limite pode ser até 480 horas, dependendo do seu cluster.

# Ativação do ambiente Conda
source /temporario2/9877294/anaconda3/etc/profile.d/conda.sh   # Carrega o Conda no shell.
conda activate                                              # Ativa o ambiente Conda configurado previamente.

# Define os diretórios de entrada e saída
base_dir="/temporario2/9877294/ncbi_dataset/data"  # Diretório onde estão os arquivos .gbff.
output_base="/temporario2/9877294/Resultados_AntiSMASH"  # Diretório onde os resultados do antiSMASH serão salvos.

mkdir -p logs  # Cria um diretório "logs" caso ainda não exista, para armazenar logs de execução.

# Criação da pipeline Nextflow
cat > pipeline.nf << 'EOF'
params.base_dir = '/temporario2/9877294/ncbi_dataset/data'  # Caminho para os arquivos de entrada .gbff.
params.output_base = '/temporario2/9877294/Resultados_AntiSMASH'  # Caminho para os resultados.

# Criação de um canal que irá buscar todos os arquivos .gbff em subdiretórios
Channel
    .fromPath("${params.base_dir}/**/genomic.gbff")  # Busca todos os arquivos genomic.gbff em qualquer subdiretório.
    .set { arquivos }  # Armazena os arquivos encontrados na variável 'arquivos'.

# Define o processo 'runAntismash' que será executado para cada arquivo encontrado
process runAntismash {
    tag "${genoma_name}"  # A tag usada para identificar cada execução (por nome do genoma).

    input:
    path arquivo from arquivos  # Recebe o arquivo de entrada do canal 'arquivos'.

    output:
    path "${genoma_name}_antismash"  # Define o diretório de saída baseado no nome do genoma.

    script:
    // Extrai o nome do diretório pai onde o arquivo está localizado, que será o nome do genoma.
    genome_dir = arquivo.toString().tokenize('/')[-2]  // Extrai o nome do diretório pai (nome do genoma).
    genoma_name = genome_dir  // Atribui o nome do genoma à variável 'genoma_name'.

    """
    mkdir -p ${genoma_name}_antismash  # Cria o diretório de saída para armazenar os resultados.
    antismash --genefinding-tool prodigal \  # Roda o antiSMASH usando o prodigal como ferramenta de predição de genes.
              --relaxed \  # Modo "relaxado" no antiSMASH para maior flexibilidade.
              "$arquivo" \  # O arquivo de entrada que está sendo processado.
              --output-dir ${genoma_name}_antismash  # Diretório de saída onde os resultados serão armazenados.
    """
}
EOF

# Criação da configuração Nextflow para SLURM
cat > nextflow.config << 'EOF'
process.executor = 'slurm'  # Define que o Nextflow deve usar o SLURM como agendador de tarefas.

process {
    cpus = 20  # Cada processo utilizará 20 CPUs (em linha com o parâmetro do SLURM).
    memory = '32 GB'  # Define que cada processo terá 32GB de memória.
    time = '40h'  # Tempo máximo de execução para cada job (40 horas).
    queue = 'SP2'  # Define a fila onde os jobs serão executados (correspondente à partição SLURM).
}

executor {
    queueSize = 100  # Número máximo de jobs que podem estar aguardando na fila.
    submitRateLimit = '1 sec'  # Limita a submissão de jobs a 1 segundo de intervalo, evitando sobrecarga.
}
EOF

# Executa a pipeline Nextflow
nextflow run pipeline.nf -resume \  # Roda a pipeline Nextflow, retomando de onde parou (caso já tenha sido executada antes).
    -with-report report.html \  # Gera um relatório HTML com estatísticas da execução.
    -with-trace trace.txt \  # Salva um arquivo de rastreamento com os tempos de execução.
    -with-timeline timeline.html \  # Cria um gráfico de tempo da execução dos processos.
    -with-dag flowchart.png  # Gera um diagrama do fluxo de execução da pipeline.
